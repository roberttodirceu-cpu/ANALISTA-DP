# app.py - Vers√£o FINAL com Corre√ß√£o da L√≥gica da Sidebar (v4.1)

import streamlit as st
import pandas as pd
import plotly.express as px
import os
import numpy as np
from datetime import datetime
from io import BytesIO
import pickle 
import re 
import unicodedata

# ==============================================================================
# IMPORTA√á√ÉO DE FUN√á√ïES ESSENCIAIS DO UTILS.PY
# ==============================================================================
# Fun√ß√µes simuladas para garantir que o c√≥digo rode mesmo sem o utils.py
def formatar_moeda(valor): 
    # Tenta lidar com NaN
    if pd.isna(valor): return "R$ 0,00"
    return f"R$ {valor:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")

def limpar_string(text):
    if pd.isna(text): return 'N/A'
    return str(text).strip()

def limpar_nome_coluna(col):
    if not isinstance(col, str): return str(col).lower()
    
    col = col.strip().lower()
    # Remove acentos e caracteres especiais (e.g., \xa0)
    col = unicodedata.normalize('NFKD', col).encode('ascii', 'ignore').decode('utf-8')
    col = re.sub(r'[^a-z0-9]+', '_', col) 
    col = col.strip('_')
    return col

def inferir_e_converter_tipos(df, cols_texto, cols_valor): 
    df_clean = df.copy()

    # 1. Limpeza e Convers√£o de Colunas de Texto/Categoria
    for col in cols_texto:
        if col in df_clean.columns:
            # Aplica limpeza para remover espa√ßos em branco invis√≠veis e padronizar
            df_clean[col] = df_clean[col].apply(limpar_string).astype('category')

    # 2. Convers√£o de Colunas de Valor (Num√©ricas)
    for col in cols_valor:
        if col in df_clean.columns:
            # Limpeza robusta para colunas de valor
            try:
                # Converte para string e remove todos os caracteres que n√£o sejam d√≠gitos, v√≠rgula ou ponto
                df_clean[col] = df_clean[col].astype(str).str.replace(r'[^\d,\.-]', '', regex=True)
                
                # Tenta lidar com a nota√ß√£o brasileira (milhar=ponto, decimal=v√≠rgula)
                if df_clean[col].str.contains(r','):
                    # Remove pontos (milhar) e substitui v√≠rgulas (decimal) por ponto
                    df_clean[col] = df_clean[col].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)
                
                # Coerce to numeric (erros se tornam NaN)
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
                df_clean[col].fillna(0, inplace=True) # Preenche NaN ap√≥s coer√ß√£o com 0
            except:
                st.warning(f"Aviso: Falha ao converter a coluna '{col}' para num√©rica.")
                
    return df_clean 

def encontrar_colunas_tipos(df): 
    # Simula√ß√£o baseada em heur√≠stica para df j√° processado
    cols_date = []
    cols_numeric = df.select_dtypes(include=np.number).columns.tolist()
    
    # Heur√≠stica para colunas de data (se tiverem ano/mes, mas est√£o como categoria)
    if 'ano' in df.columns and 'mes' in df.columns and 'mes' in df.select_dtypes(include=['category', 'object']).columns:
        cols_date = ['ano', 'mes']

    return cols_numeric, cols_date

def gerar_rotulo_filtro(df_completo, filtros_ativos, colunas_data, data_range): 
    if not filtros_ativos: return "NENHUM FILTRO CATEG√ìRICO ATIVO (Todos os dados est√£o inclusos)."
    
    rotulo = []
    for col, valores in filtros_ativos.items():
        if valores and len(valores) > 0:
            # Obter todas as op√ß√µes √∫nicas do DF completo para a coluna
            opcoes_unicas = df_completo[col].astype(str).fillna('N/A').unique().tolist()
            
            # Se a sele√ß√£o for a totalidade das op√ß√µes, ignora (n√£o √© um filtro)
            if len(valores) == len(opcoes_unicas):
                continue

            rotulo.append(f"**{col.title()}:** {', '.join(sorted(valores))[:100]}...") # Limita a 100 caracteres

    if not rotulo:
        return "NENHUM FILTRO CATEG√ìRICO ATIVO (Todas as op√ß√µes foram selecionadas)."

    return "<br>".join(rotulo)

def verificar_ausentes(df): return {} # Simplifica√ß√£o para o app.py


# ==============================================================================

# --- Configura√ß√£o da P√°gina e Persist√™ncia ---
st.set_page_config(layout="wide", page_title="Sistema de An√°lise de Indicadores Expert")
# Nota: O caminho de persist√™ncia deve ser alterado se voc√™ n√£o estiver usando o ambiente padr√£o do Streamlit
PERSISTENCE_PATH = 'data/data_sets_catalog.pkl' 

# ==============================================================================
# FUN√á√ïES DE GERENCIAMENTO DE ESTADO E PERSIST√äNCIA
# ==============================================================================

def load_catalog():
    if os.path.exists(PERSISTENCE_PATH):
        try:
            with open(PERSISTENCE_PATH, 'rb') as f:
                return pickle.load(f)
        except Exception:
            return {}
    return {}

def save_catalog(catalog):
    try:
        # Garante que o diret√≥rio exista
        os.makedirs(os.path.dirname(PERSISTENCE_PATH), exist_ok=True) 
        with open(PERSISTENCE_PATH, 'wb') as f:
            pickle.dump(catalog, f)
    except Exception as e:
        st.sidebar.error(f"Erro ao salvar dados de persist√™ncia: {e}")

def limpar_filtros_salvos():
    """Limpa o estado de todos os filtros, for√ßando os widgets a resetarem ao default."""
    st.session_state.active_filters_base = {}
    st.session_state.active_filters_comp = {}
    
    # Incrementa o trigger para for√ßar a reexecu√ß√£o e rec√°lculo dos filtros cacheados
    st.session_state['filtro_reset_trigger'] += 1
    
    # Limpa as chaves de sess√£o para os widgets de filtro e data
    chaves_a_limpar = [
        key for key in st.session_state.keys() 
        if key.startswith('filtro_key_base_') or key.startswith('date_range_key_base_') or 
           key.startswith('filtro_key_comp_') or key.startswith('date_range_key_comp_')
    ]
    for key in chaves_a_limpar:
        try:
            del st.session_state[key]
        except:
            pass
            
    st.rerun() 

def set_multiselect_all(key, suffix, options_list):
    """Callback para o bot√£o 'Selecionar Tudo'."""
    st.session_state[f'filtro_key_{suffix}_{key}'] = options_list
    

def set_multiselect_none(key, suffix):
    """Callback para o bot√£o 'Limpar'."""
    st.session_state[f'filtro_key_{suffix}_{key}'] = []
    
def switch_dataset(dataset_name):
    """Troca o dataset ativo no dashboard."""
    if dataset_name in st.session_state.data_sets_catalog:
        data = st.session_state.data_sets_catalog[dataset_name]
        st.session_state.dados_atuais = data['df']
        st.session_state.colunas_filtros_salvas = data['colunas_filtros_salvas']
        st.session_state.colunas_valor_salvas = data['colunas_valor_salvas']
        st.session_state.current_dataset_name = dataset_name
        
        default_exclude = [col for col in data['df'].columns if col in ['emp', 'eve', 'seq', 'nr_func']]
        st.session_state.cols_to_exclude_analysis = default_exclude
        
        limpar_filtros_salvos()
    else:
        st.error(f"Dataset '{dataset_name}' n√£o encontrado.")

def show_reconfig_panel():
    st.session_state.show_reconfig_section = True
    
def processar_dados_atuais(df_novo, colunas_filtros, colunas_valor, dataset_name):
    base_name = dataset_name if dataset_name else f"Dataset Processado ({datetime.now().strftime('%Y-%m-%d %H:%M')})"
        
    st.session_state.data_sets_catalog[base_name] = {
        'df': df_novo,
        'colunas_filtros_salvas': colunas_filtros,
        'colunas_valor_salvas': colunas_valor,
    }
    
    save_catalog(st.session_state.data_sets_catalog)
    
    st.session_state.dados_atuais = df_novo 
    st.session_state.colunas_filtros_salvas = colunas_filtros
    st.session_state.colunas_valor_salvas = colunas_valor
    st.session_state.current_dataset_name = base_name 
    
    default_exclude = [col for col in df_novo.columns if col in ['emp', 'eve', 'seq', 'nr_func']]
    st.session_state.cols_to_exclude_analysis = default_exclude
    
    return True, df_novo

def initialize_widget_state(key, initial_default_calc):
    if key not in st.session_state:
        st.session_state[key] = initial_default_calc
# ==============================================================================

# --- Inicializa√ß√£o de Estado da Sess√£o ---
if 'data_sets_catalog' not in st.session_state: st.session_state.data_sets_catalog = load_catalog()
if 'filtro_reset_trigger' not in st.session_state: st.session_state['filtro_reset_trigger'] = 0

initial_df = pd.DataFrame()
initial_filters = []
initial_values = []
initial_name = ""
if st.session_state.data_sets_catalog:
    last_name = list(st.session_state.data_sets_catalog.keys())[-1]
    data = st.session_state.data_sets_catalog[last_name]
    initial_df = data['df']
    initial_filters = data['colunas_filtros_salvas']
    initial_values = data['colunas_valor_salvas']
    initial_name = last_name

if 'dados_atuais' not in st.session_state: st.session_state.dados_atuais = initial_df
if 'colunas_filtros_salvas' not in st.session_state: st.session_state.colunas_filtros_salvas = initial_filters
if 'colunas_valor_salvas' not in st.session_state: st.session_state.colunas_valor_salvas = initial_values
if 'current_dataset_name' not in st.session_state: st.session_state.current_dataset_name = initial_name
    
if 'uploaded_files_data' not in st.session_state: st.session_state.uploaded_files_data = {} 
if 'df_filtrado_base' not in st.session_state: st.session_state.df_filtrado_base = initial_df.copy()
if 'df_filtrado_comp' not in st.session_state: st.session_state.df_filtrado_comp = initial_df.copy()
if 'show_reconfig_section' not in st.session_state: st.session_state.show_reconfig_section = False
if 'active_filters_base' not in st.session_state: st.session_state.active_filters_base = {} 
if 'active_filters_comp' not in st.session_state: st.session_state.active_filters_comp = {} 
if 'cols_to_exclude_analysis' not in st.session_state: 
    st.session_state.cols_to_exclude_analysis = [col for col in initial_df.columns if col in ['emp', 'eve', 'seq', 'nr_func']]


# --- Aplica√ß√£o de Filtros (Fun√ß√£o Caching) ---
@st.cache_data(show_spinner="Aplicando filtros de Base e Compara√ß√£o...")
def aplicar_filtros_comparacao(df_base, col_filtros, filtros_ativos_base, filtros_ativos_comp, col_data, data_range_base, data_range_comp, trigger):
    
    # data_range_base e data_range_comp s√£o passados como None (porque o slider foi removido)

    def _aplicar_filtro_single(df, col_filtros_list, filtros_ativos_dict):
        df_filtrado_temp = df.copy()
        
        # 1. Filtros Categ√≥ricos
        for col in col_filtros_list:
            selecao = filtros_ativos_dict.get(col)
            if col not in df_filtrado_temp.columns: continue

            opcoes_unicas = df_base[col].astype(str).fillna('N/A').unique().tolist()
            
            # Aplica filtro SOMENTE se a sele√ß√£o n√£o estiver vazia E n√£o for total
            if selecao and len(selecao) > 0 and len(selecao) < len(opcoes_unicas): 
                # Converte a coluna para string para garantir a filtragem categ√≥rica
                df_filtrado_temp = df_filtrado_temp[df_filtrado_temp[col].astype(str).isin(selecao)]
        
        return df_filtrado_temp
    
    # Passamos apenas as listas de filtros categ√≥ricos
    df_base_filtrado = _aplicar_filtro_single(df_base, col_filtros, filtros_ativos_base)
    df_comp_filtrado = _aplicar_filtro_single(df_base, col_filtros, filtros_ativos_comp)
    
    # Retornamos os DataFrames filtrados
    return df_base_filtrado, df_comp_filtrado


# --- FUN√á√ÉO PARA TABELA DE RESUMO E M√âTRICAS "EXPERT" ---

def calcular_venc_desc(df):
    col_tipo_evento = 't' 
    col_valor = 'valor' 
    col_func = 'nome_funcionario' # Chave para Funcion√°rio √önico

    if df.empty or col_valor not in df.columns or col_tipo_evento not in df.columns:
        return 0, 0, 0, 0
        
    df_clean = df.copy()

    # <--- CORRE√á√ÉO CR√çTICA DO TypeError: Garantir que a coluna 'valor' √© num√©rica --->
    try:
        # For√ßa a coluna 'valor' a ser num√©rica, transformando valores inv√°lidos (strings, etc.) em NaN, 
        # e depois preenche NaN com 0 para que a soma funcione corretamente.
        df_clean[col_valor] = pd.to_numeric(df_clean[col_valor], errors='coerce').fillna(0)
    except Exception as e:
        # Se falhar, retorna 0 para evitar quebra total do app
        st.warning(f"Falha cr√≠tica ao for√ßar coluna 'valor' para num√©rico na an√°lise: {e}")
        return 0, 0, 0, 0
    # <--- FIM DA CORRE√á√ÉO CR√çTICA --->

    df_clean = df_clean.dropna(subset=[col_valor, col_tipo_evento])

    vencimentos = df_clean[df_clean[col_tipo_evento] == 'C'][col_valor].sum()
    descontos = df_clean[df_clean[col_tipo_evento] == 'D'][col_valor].sum()
    
    # Esta subtra√ß√£o agora √© segura, pois vencimentos e descontos s√£o resultados de .sum() em uma coluna float.
    liquido = vencimentos - descontos 
    
    # L√≥gica de contagem de Funcion√°rios √önicos
    func_count = df_clean[col_func].astype(str).str.strip().replace('', np.nan).dropna().nunique()

    return vencimentos, descontos, liquido, func_count

def gerar_analise_expert(df_completo, df_base, df_comp, filtros_ativos_base, filtros_ativos_comp, colunas_data, data_range_base, data_range_comp):
    
    colunas_valor_salvas = st.session_state.colunas_valor_salvas
    
    # -------------------------------------------------------------
    # 1. AN√ÅLISE DE CONTEXTO E R√ìTULOS DETALHADOS
    # -------------------------------------------------------------
    st.markdown("#### üìù Contexto do Filtro Ativo")
    
    # A fun√ß√£o gerar_rotulo_filtro foi ajustada para aceitar None para data_range
    rotulo_base = gerar_rotulo_filtro(df_completo, filtros_ativos_base, colunas_data, data_range_base)
    rotulo_comp = gerar_rotulo_filtro(df_completo, filtros_ativos_comp, colunas_data, data_range_comp)

    st.markdown(f"""
        <div style="padding: 10px; border: 1px solid #007bff; border-radius: 5px; margin-bottom: 15px; background-color: #e9f7ff;">
            <p style="margin: 0; font-weight: bold; font-size: 16px;"><span style="color: #007bff;">BASE (Refer√™ncia):</span></p>
            <p style="margin: 0; font-size: 14px;">{rotulo_base}</p>
        </div>
        <div style="padding: 10px; border: 1px solid #6f42c1; border-radius: 5px; margin-bottom: 20px; background-color: #f6f0ff;">
            <p style="margin: 0; font-weight: bold; font-size: 16px;"><span style="color: #6f42c1;">COMPARA√á√ÉO (Alvo):</span></p>
            <p style="margin: 0; font-size: 14px;">{rotulo_comp}</p>
        </div>
    """, unsafe_allow_html=True)

    # -------------------------------------------------------------
    # 2. CALCULO DE VENCIMENTOS E DESCONTOS E FUNCION√ÅRIOS √öNICOS
    # -------------------------------------------------------------
    
    col_func = 'nome_funcionario' # Chave para Funcion√°rio √önico
    
    # VERIFICA√á√ÉO DE FUNCION√ÅRIOS √öNICOS
    if col_func not in df_completo.columns:
        st.error(f"Erro Cr√≠tico: A coluna '{col_func}' n√£o foi encontrada no DataFrame. O pr√©-processamento de nomes de coluna falhou. Limpe o cache e tente novamente. Colunas atuais: {df_completo.columns.tolist()}")
        return

    # Base
    venc_base, desc_base, liq_base, func_base = calcular_venc_desc(df_base)
    
    # Compara√ß√£o
    venc_comp, desc_comp, liq_comp, func_comp = calcular_venc_desc(df_comp)
    
    # Total Geral
    venc_total, desc_total, liq_total, func_total = calcular_venc_desc(df_completo)


    # -------------------------------------------------------------
    # 3. APRESENTA√á√ÉO DOS KPIS DE VENCIMENTOS E DESCONTOS (CARDS)
    # -------------------------------------------------------------
    st.markdown("##### üí∞ Resumo Financeiro da BASE (Refer√™ncia)")
    col1, col2, col3, col4 = st.columns(4)

    # Fun√ß√£o auxiliar para calcular e formatar a varia√ß√£o percentual
    def get_delta(comp, base, is_currency=True):
        diff = comp - base
        if base == 0:
            pct_diff = 0 if comp == 0 else np.inf
        else:
            pct_diff = (diff / base) * 100
            
        if is_currency:
            return formatar_moeda(diff).replace('R$', ''), f" ({pct_diff:,.2f}%)" if np.isfinite(pct_diff) else " (N/A)"
        else:
            return f"{diff:,.0f}".replace(",", "X").replace(".", ",").replace("X", "."), f" ({pct_diff:,.2f}%)" if np.isfinite(pct_diff) else " (N/A)"


    # KPI 1: Contagem de Funcion√°rios (Base)
    delta_func_val, delta_func_pct = get_delta(func_comp, func_base, is_currency=False)
    col1.metric(
        label=f"Funcion√°rios √önicos (Total: {func_total})", 
        value=f"{func_base:,.0f}".replace(",", "X").replace(".", ",").replace("X", "."), 
        delta=f"{delta_func_val} {delta_func_pct}"
    )

    # KPI 2: Total de Vencimentos (Base)
    delta_venc_val, delta_venc_pct = get_delta(venc_comp, venc_base, is_currency=True)
    col2.metric(
        label=f"Total Vencimentos (Total: {formatar_moeda(venc_total)})", 
        value=formatar_moeda(venc_base), 
        delta=f"{delta_venc_val} {delta_venc_pct}"
    )

    # KPI 3: Total de Descontos (Base)
    delta_desc_val, delta_desc_pct = get_delta(desc_comp, desc_base, is_currency=True)
    col3.metric(
        label=f"Total Descontos (Total: {formatar_moeda(desc_total)})", 
        value=formatar_moeda(desc_base), 
        delta=f"{delta_desc_val} {delta_desc_pct}"
    )
    
    # KPI 4: L√≠quido (Base)
    delta_liq_val, delta_liq_pct = get_delta(liq_comp, liq_base, is_currency=True)
    col4.metric(
        label=f"Valor L√≠quido (Total: {formatar_moeda(liq_total)})", 
        value=formatar_moeda(liq_base), 
        delta=f"{delta_liq_val} {delta_liq_pct}"
    )

    st.markdown("---")


    # -------------------------------------------------------------
    # 4. TABELA DE VARIA√á√ÉO DETALHADA
    # -------------------------------------------------------------

    dados_resumo = []
    
    # 4.1. Adiciona M√©tricas Espec√≠ficas
    dados_resumo.append({'M√©trica': 'CONT. DE REGISTROS', 'Total Geral': len(df_completo), 'Base (Filtrado)': len(df_base), 'Compara√ß√£o (Filtrado)': len(df_comp), 'Tipo': 'Contagem'})
    dados_resumo.append({'M√©trica': 'CONT. DE FUNCION√ÅRIOS √öNICOS', 'Total Geral': func_total, 'Base (Filtrado)': func_base, 'Compara√ß√£o (Filtrado)': func_comp, 'Tipo': 'Contagem'})
    dados_resumo.append({'M√©trica': 'TOTAL DE VENCIMENTOS (CR√âDITO)', 'Total Geral': venc_total, 'Base (Filtrado)': venc_base, 'Compara√ß√£o (Filtrado)': venc_comp, 'Tipo': 'Moeda'})
    dados_resumo.append({'M√©trica': 'TOTAL DE DESCONTOS (D√âBITO)', 'Total Geral': desc_total, 'Base (Filtrado)': desc_base, 'Compara√ß√£o (Filtrado)': desc_comp, 'Tipo': 'Moeda'})
    dados_resumo.append({'M√©trica': 'VALOR L√çQUIDO (Venc - Desc)', 'Total Geral': liq_total, 'Base (Filtrado)': liq_base, 'Compara√ß√£o (Filtrado)': liq_comp, 'Tipo': 'Moeda'})

    colunas_moeda_outras = [col for col in st.session_state.colunas_valor_salvas if col not in ['valor']] 
    for col in colunas_moeda_outras:
        total_geral_soma = df_completo[col].sum()
        total_base_soma = df_base[col].sum()
        total_comp_soma = df_comp[col].sum()
        dados_resumo.append({'M√©trica': f"SOMA: {col.upper().replace('_', ' ')}", 'Total Geral': total_geral_soma, 'Base (Filtrado)': total_base_soma, 'Compara√ß√£o (Filtrado)': total_comp_soma, 'Tipo': 'Moeda'})
            
    df_resumo = pd.DataFrame(dados_resumo)
    
    def calcular_variacao(row):
        base = row['Base (Filtrado)']
        comp = row['Compara√ß√£o (Filtrado)']
        
        if base == 0:
            return 0 if comp == 0 else np.inf
        return ((comp - base) / base) * 100

    df_resumo['Varia√ß√£o %'] = df_resumo.apply(calcular_variacao, axis=1)

    df_tabela = df_resumo.copy()
    
    def format_value(row, col_name):
        val = row[col_name]
        if row['Tipo'] == 'Moeda':
            return formatar_moeda(val)
        else:
            return f"{val:,.0f}".replace(",", "X").replace(".", ",").replace("X", ".")
            
    df_tabela['TOTAL GERAL (Sem Filtro)'] = df_tabela.apply(lambda row: format_value(row, 'Total Geral'), axis=1)
    df_tabela['BASE (FILTRADO)'] = df_tabela.apply(lambda row: format_value(row, 'Base (Filtrado)'), axis=1)
    df_tabela['COMPARA√á√ÉO (FILTRADO)'] = df_tabela.apply(lambda row: format_value(row, 'Compara√ß√£o (Filtrado)'), axis=1)

    def format_variacao_tabela(val):
        if not np.isfinite(val):
            return '<span style="color: gray;">N/A</span>'
        
        val_str = f"{val:,.2f} %".replace(",", "X").replace(".", ",").replace("X", ".")
        
        if val > 0:
            color = 'green'
            icon = '‚ñ≤'
        elif val < 0:
            color = 'red'
            icon = '‚ñº'
        else:
            color = 'gray'
            icon = '‚Äî'
            
        return f'<span style="color: {color}; font-weight: bold;">{icon} {val_str}</span>'

    df_tabela['VARIA√á√ÉO BASE vs COMP (%)'] = df_tabela['Varia√ß√£o %'].apply(format_variacao_tabela)
    
    df_final_exibicao = df_tabela[['M√©trica', 'TOTAL GERAL (Sem Filtro)', 'BASE (FILTRADO)', 'COMPARA√á√ÉO (FILTRADO)', 'VARIA√á√ÉO BASE vs COMP (%)']]

    st.markdown("##### üîç Comparativo Detalhado de M√©tricas Chave")
    st.markdown(df_final_exibicao.to_html(escape=False, index=False), unsafe_allow_html=True)


# --- SIDEBAR (CONFIGURA√á√ïES E UPLOAD) ---
with st.sidebar:
    st.markdown("# üìä")
    st.title("‚öôÔ∏è Configura√ß√µes do Expert")
    
    if st.button("Limpar Cache de Dados e Persist√™ncia"):
        st.cache_data.clear()
        if os.path.exists(PERSISTENCE_PATH):
            try:
                os.remove(PERSISTENCE_PATH)
                st.session_state.data_sets_catalog = {}
                st.session_state.dados_atuais = pd.DataFrame()
                st.sidebar.success("Cache e dados de persist√™ncia limpos.")
            except Exception as e:
                st.sidebar.error(f"Erro ao remover arquivo de persist√™ncia: {e}")
        
        # Limpa todas as chaves de sess√£o para um estado inicial limpo
        keys_to_clear = [k for k in st.session_state.keys() if not k.startswith('_')]
        for key in keys_to_clear:
            if key not in ['data_sets_catalog', 'dados_atuais']:
                try:
                    del st.session_state[key]
                except:
                    pass
        st.info("Estado da sess√£o limpo! Recarregando...")
        st.rerun()

    # Se√ß√£o 1: Trocar Dataset Ativo (Aparece SOMENTE se houver dados salvos)
    if st.session_state.data_sets_catalog:
        st.header("1. Trocar Dataset Ativo")
        dataset_names = list(st.session_state.data_sets_catalog.keys())
        
        current_index = dataset_names.index(st.session_state.current_dataset_name) if st.session_state.current_dataset_name in dataset_names else 0
        
        selected_name = st.selectbox(
            "Selecione o Dataset Ativo:", 
            options=dataset_names, 
            index=current_index,
            key='sidebar_dataset_selector'
        )
        
        if selected_name != st.session_state.current_dataset_name:
            switch_dataset(selected_name)
            
    # Se√ß√£o 2: Upload e Processamento
    st.header("2. Upload e Processamento")
    
    # Input para nome do Dataset, mantido em session_state para persistir durante o upload
    if 'current_dataset_name_input' not in st.session_state:
        st.session_state.current_dataset_name_input = f"Dataset Processado ({datetime.now().strftime('%Y-%m-%d %H:%M')})"
        
    with st.form("file_upload_form", clear_on_submit=True):
        uploaded_files_new = st.file_uploader(
            "üì• Carregar Novo(s) CSV/XLSX", 
            type=['csv', 'xlsx'], 
            accept_multiple_files=True,
            key="file_uploader_widget"
        )
        
        dataset_name_input = st.text_input("Nome para o Novo Dataset (Ou o nome do que ser√° somado):", 
                                           value=st.session_state.current_dataset_name_input)
        st.session_state.current_dataset_name_input = dataset_name_input # Atualiza o estado

        submit_upload = st.form_submit_button("Adicionar Arquivo(s) √† Lista")
        
        if submit_upload and uploaded_files_new:
            newly_added = []
            for file in uploaded_files_new:
                # Adiciona os arquivos √† lista de pendentes para processamento
                st.session_state.uploaded_files_data[file.name] = file.read()
                newly_added.append(file.name)
            st.success(f"Arquivos adicionados: {', '.join(newly_added)}. Clique em 'Processar' abaixo.")
            
            # CR√çTICO: For√ßa a exibi√ß√£o da se√ß√£o de reconfigura√ß√£o
            st.session_state.show_reconfig_section = True 
            st.rerun()

    
    # CR√çTICO: Esta se√ß√£o agora √© exibida se houver arquivos pendentes OU se o estado show_reconfig_section for True
    if st.session_state.uploaded_files_data or st.session_state.show_reconfig_section:
        
        # O bot√£o de reconfigura√ß√£o aparece se tivermos arquivos pendentes (uploaded_files_data)
        if st.session_state.uploaded_files_data:
            st.markdown("---")
            st.markdown("##### üìù Arquivos Pendentes:")
            for file_name in st.session_state.uploaded_files_data.keys():
                st.markdown(f"- **{file_name}**")
            
            # Bot√£o para for√ßar a reabertura do painel, caso tenha sido fechado
            st.button("üîÅ Iniciar Configura√ß√£o e Processamento", 
                      on_click=show_reconfig_panel,
                      key='reconfig_btn_sidebar',
                      use_container_width=True,
                      type='primary')
            st.markdown("---")
        
        # Este √© o painel de configura√ß√£o que aparece AP√ìS o clique no bot√£o acima ou ap√≥s um upload
        if st.session_state.show_reconfig_section:
            
            # Se n√£o houver dados, mas show_reconfig_section for True (erro de estado), for√ßamos o DF a ser criado
            df_novo = pd.DataFrame()
            all_dataframes = []
            
            # --- L√ìGICA DE CARREGAMENTO PARA CONCATENA√á√ÉO (SOMA DE DADOS) ---
            df_atual_base = pd.DataFrame()
            dataset_name_to_use = st.session_state.get('current_dataset_name_input', f"Dataset Processado ({datetime.now().strftime('%Y-%m-%d %H:%M')}")

            # --- NOVO SELETOR PARA CONCATENA√á√ÉO ---
            st.markdown("##### ‚ûï Op√ß√£o de Soma/Agrega√ß√£o")
            
            # Lista de datasets dispon√≠veis
            catalog_names = ["Criar Novo Dataset (Substituir/Criar)"] + list(st.session_state.data_sets_catalog.keys())
            
            selected_dataset_to_sum = st.selectbox(
                "Somar arquivos carregados com qual Dataset existente?",
                options=catalog_names,
                index=0,
                key='dataset_to_sum_selector'
            )
            
            # L√≥gica para definir o nome final do dataset
            if selected_dataset_to_sum != "Criar Novo Dataset (Substituir/Criar)":
                dataset_name_to_use = selected_dataset_to_sum
                st.session_state.current_dataset_name_input = dataset_name_to_use 
                st.info(f"Os novos dados ser√£o SOMADOS ao dataset **{dataset_name_to_use}**.")
            else:
                dataset_name_to_use = st.session_state.get('current_dataset_name_input')

            # 1. Tenta carregar o dataset ATIVO ESCOLHIDO para soma
            if selected_dataset_to_sum != "Criar Novo Dataset (Substituir/Criar)":
                if dataset_name_to_use in st.session_state.data_sets_catalog:
                    df_atual_base = st.session_state.data_sets_catalog[dataset_name_to_use]['df'].copy()
                    
            # 2. Processa o(s) novo(s) arquivo(s)
            if not st.session_state.uploaded_files_data:
                # Se o painel est√° aberto, mas n√£o h√° dados pendentes, √© um erro de estado ou uma reconfigura√ß√£o da base atual
                st.warning("Nenhum novo arquivo detectado para processamento.")
                
            else:
                for file_name, file_bytes in st.session_state.uploaded_files_data.items():
                    df_temp = None 
                    
                    try:
                        uploaded_file_stream = BytesIO(file_bytes)
                        
                        if file_name.endswith('.csv'):
                            reading_attempts = [
                                {'sep': ';', 'decimal': ',', 'encoding': 'utf-8', 'skipinitialspace': True, 'header': 'infer'},
                                # CR√çTICO: Op√ß√µes de skip row 1 para contornar lixo invis√≠vel
                                {'sep': ';', 'decimal': ',', 'encoding': 'iso-8859-1', 'skipinitialspace': True, 'header': None, 'skiprows': 1},
                                {'sep': ',', 'decimal': '.', 'encoding': 'utf-8', 'skipinitialspace': True, 'header': None, 'skiprows': 1},
                                
                                # Outras combina√ß√µes normais
                                {'sep': ';', 'decimal': ',', 'encoding': 'latin-1', 'skipinitialspace': True, 'header': 'infer'},
                                {'sep': ',', 'decimal': '.', 'encoding': 'utf-8', 'skipinitialspace': True, 'header': 'infer'},
                                {'sep': ',', 'decimal': '.', 'encoding': 'latin-1', 'skipinitialspace': True, 'header': 'infer'},
                                {'sep': ';', 'decimal': ',', 'encoding': 'iso-8859-1', 'skipinitialspace': True, 'header': 'infer'},
                                {'sep': ',', 'decimal': '.', 'encoding': 'iso-8859-1', 'skipinitialspace': True, 'header': 'infer'},
                                {'sep': ';', 'decimal': '.', 'encoding': 'utf-8', 'skipinitialspace': True, 'header': 'infer'}, 
                                {'sep': '\t', 'decimal': ',', 'encoding': 'utf-8', 'skipinitialspace': True, 'header': 'infer'}, 
                            ]
                            
                            success = False
                            for attempt in reading_attempts:
                                try:
                                    uploaded_file_stream.seek(0)
                                    header_param = attempt.pop('header', 'infer')
                                    skiprows_param = attempt.pop('skiprows', 0)
                                    
                                    df_temp = pd.read_csv(
                                        uploaded_file_stream, 
                                        **attempt, 
                                        header=(0 if header_param == 'infer' else header_param),
                                        skiprows=skiprows_param
                                    )
                                    
                                    if df_temp.shape[1] > 1 and not df_temp.empty:
                                        if skiprows_param == 1 and header_param is None:
                                            # Se pulamos o cabe√ßalho, garantimos um nome de coluna
                                            df_temp.columns = [f'col_{i}' for i in range(len(df_temp.columns))]
                                            
                                        success = True
                                        break
                                    else:
                                        df_temp = None 
    
                                except Exception:
                                    pass 
                                    
                            if not success:
                                st.error(f"Falha CR√çTICA ao ler o arquivo CSV '{file_name}'. Ele ser√° ignorado.")
    
                                    
                        elif file_name.endswith('.xlsx'):
                            try:
                                df_temp = pd.read_excel(uploaded_file_stream)
                                if df_temp is not None and not df_temp.empty: 
                                    st.sidebar.success(f"Arquivo '{file_name}' lido com sucesso (Excel).")
                            except ImportError:
                                 st.error(f"Erro ao ler o XLSX '{file_name}': Missing optional dependency 'openpyxl'.")
                            except Exception as inner_e:
                                st.error(f"Erro ao ler o XLSX '{file_name}': {inner_e}")
                                
                        
                        if df_temp is not None and not df_temp.empty: 
                            all_dataframes.append(df_temp)
    
                    except Exception as e:
                        st.error(f"Erro inesperado no processamento do arquivo {file_name}. Ele ser√° ignorado. Detalhe: {e}")
                        pass 

                if all_dataframes:
                    df_novo_upload = pd.concat(all_dataframes, ignore_index=True)
                    
                    # <------------------------- DEBUG DE LEITURA ------------------------->
                    st.sidebar.warning(f"DEBUG: df_novo_upload (Dados Carregados) lido com {len(df_novo_upload)} linhas.")
                    # <--------------------------------------------------------------------->

                    # 3. Concatena o novo upload com o dataset base existente, se houver
                    if not df_atual_base.empty:
                        # Aplica a limpeza de colunas no DF atual para garantir que os nomes correspondam
                        raw_columns_base = df_atual_base.columns.copy()
                        cleaned_columns_base = [limpar_nome_coluna(col) for col in raw_columns_base]
                        df_atual_base.columns = cleaned_columns
                        
                        # Concatena a base existente com o novo upload
                        df_novo = pd.concat([df_atual_base, df_novo_upload], ignore_index=True)
                        st.sidebar.info(f"CONCATENA√á√ÉO: {len(df_atual_base)} (Existente) + {len(df_novo_upload)} (Novo) = {len(df_novo)} linhas totais.")
                    else:
                        df_novo = df_novo_upload 
                
            if df_novo.empty:
                st.error("O conjunto de dados consolidado est√° vazio. Verifique se os arquivos foram lidos corretamente acima.")
                st.session_state.dados_atuais = pd.DataFrame() 
            else:
                
                # --- CORRE√á√ÉO DE LIMPEZA MAIS ROBUSTA (Padroniza√ß√£o de Colunas) ---
                raw_columns = df_novo.columns.copy()
                cleaned_columns = [limpar_nome_coluna(col) for col in raw_columns]
                df_novo.columns = cleaned_columns
                colunas_disponiveis = df_novo.columns.tolist()

                # --- VERIFICA√á√ÉO E RENOMEA√á√ÉO FOR√áADA DE 'NOME FUNCIONARIO' ---
                target_col = 'nome_funcionario'
                
                if target_col not in colunas_disponiveis:
                    employee_col_candidates = [col for col in colunas_disponiveis if 'nome' in col and 'func' in col]

                    if employee_col_candidates:
                        original_candidate = employee_col_candidates[0]
                        df_novo.rename(columns={original_candidate: target_col}, inplace=True)
                        st.sidebar.info(f"Col. de Funcion√°rio renomeada: '{original_candidate}' -> '{target_col}'")
                        colunas_disponiveis = df_novo.columns.tolist() 
                    else:
                        st.sidebar.warning("Aviso: N√£o foi poss√≠vel identificar a coluna de nome de funcion√°rio automaticamente.")
                        
                # --- FIM DA CORRE√á√ÉO CR√çTICA ---
                
                st.info(f"Total de {len(df_novo)} linhas para configurar.")
                
                moeda_default = [col for col in colunas_disponiveis if any(word in col for word in ['valor', 'salario', 'custo', 'receita', 'montante'])]
                if 'moeda_select' not in st.session_state: initialize_widget_state('moeda_select', moeda_default)
                
                
                # --- DEFINI√á√ÉO DE COLUNAS TEXTO (INCLUINDO M√äS E ANO) ---
                texto_default_base = ['nr_func', 'nome_funcionario', 'emp', 'eve', 'seq', 't', 'tip', 'descricao_evento', 'tipo_processo']
                
                for col_name in ['mes', 'ano']:
                    if col_name in colunas_disponiveis: texto_default_base.append(col_name)

                texto_default = [col for col in colunas_disponiveis if col in texto_default_base]

                if 'texto_select' not in st.session_state: 
                    initialize_widget_state('texto_select', texto_default)
                else:
                    current_list = st.session_state.texto_select
                    for col in texto_default:
                        if col in colunas_disponiveis and col not in current_list:
                             current_list.append(col)
                    st.session_state.texto_select = list(set(current_list)) 

                
                st.markdown("##### üí∞ Colunas de VALOR (R$)")
                colunas_moeda = st.multiselect("Selecione:", options=colunas_disponiveis, default=st.session_state.moeda_select, key='moeda_select', label_visibility="collapsed")
                
                st.markdown("---")
                st.markdown("##### üìù Colunas TEXTO/ID")
                colunas_texto = st.multiselect("Selecione:", options=colunas_disponiveis, default=st.session_state.texto_select, key='texto_select', label_visibility="collapsed")
                st.markdown("---")
                
                # O df_processado agora ter√° mes e ano como Object/Category
                df_processado = inferir_e_converter_tipos(df_novo, colunas_texto, colunas_moeda)
                
                colunas_para_filtro_options = df_processado.select_dtypes(include=['object', 'category']).columns.tolist()
                
                # --- DEFINI√á√ÉO DE FILTROS PADR√ÉO (INCLUINDO M√äS E ANO) ---
                filtro_default_base = ['t', 'descricao_evento', 'nome_funcionario', 'emp', 'tipo_processo']
                if 'mes' in colunas_para_filtro_options: filtro_default_base.append('mes')
                if 'ano' in colunas_para_filtro_options: filtro_default_base.append('ano')
                
                filtro_default = [c for c in colunas_para_filtro_options if c in filtro_default_base]
                
                if 'filtros_select' not in st.session_state:
                    initialize_widget_state('filtros_select', filtro_default)
                
                st.markdown("##### ‚öôÔ∏è Colunas para FILTROS")
                colunas_para_filtro = st.multiselect("Selecione:", options=colunas_para_filtro_options, default=st.session_state.filtros_select, key='filtros_select', label_visibility="collapsed")
                
                colunas_valor_dashboard = df_processado.select_dtypes(include=np.number).columns.tolist()
                st.markdown("---")
                
                if st.button("‚úÖ Processar e Exibir Dados Atuais", key='processar_sidebar_btn'): 
                    if df_processado.empty:
                        st.error("O DataFrame est√° vazio ap√≥s o processamento.")
                    elif not colunas_para_filtro:
                        st.warning("Selecione pelo menos uma coluna na se√ß√£o 'Colunas para FILTROS'.")
                    else:
                        
                        # --- DEFINE O NOME FINAL DO DATASET ---
                        if selected_dataset_to_sum != "Criar Novo Dataset (Substituir/Criar)":
                            final_dataset_name = selected_dataset_to_sum # Mant√©m o nome do dataset que foi agregado
                        else:
                            final_dataset_name = dataset_name_to_use # Usa o nome digitado para um novo dataset
                            
                        sucesso, df_processado_salvo = processar_dados_atuais(df_processado, colunas_para_filtro, colunas_valor_dashboard, final_dataset_name)
                        
                        if sucesso:
                            st.success(f"Dataset '{st.session_state.current_dataset_name}' processado e salvo no cat√°logo!")
                            
                            # CR√çTICO: Limpa os dados pendentes e esconde o painel de reconfigura√ß√£o
                            st.session_state.uploaded_files_data = {} 
                            st.session_state.show_reconfig_section = False
                            
                            st.balloons()
                            limpar_filtros_salvos() 
                            st.rerun() 
            
    else: 
        # Garante que o painel de reconfigura√ß√£o esteja fechado se n√£o houver arquivos pendentes
        st.session_state.show_reconfig_section = False 
        if not st.session_state.data_sets_catalog:
             st.info("Sistema pronto. O Dashboard ser√° exibido ap√≥s carregar, processar e selecionar um Dataset.")


# --- Dashboard Principal ---

st.markdown("---") 

if st.session_state.dados_atuais.empty: 
    st.info("Sistema pronto. O Dashboard ser√° exibido ap√≥s carregar, processar e selecionar um Dataset.")
else:
    df_analise_completo = st.session_state.dados_atuais.copy()
    st.header(f"üìä Dashboard Expert de An√°lise de Indicadores ({st.session_state.current_dataset_name})")
    
    colunas_categoricas_filtro = st.session_state.colunas_filtros_salvas
    
    # Colunas de data n√£o s√£o usadas para o SLIDER, mas ainda s√£o necess√°rias para o r√≥tulo
    _, colunas_data = encontrar_colunas_tipos(df_analise_completo) 
    
    st.markdown("#### üîç Configura√ß√£o de An√°lise de Varia√ß√£o")
    col_reset_btn = st.columns([4, 1])[1]
    with col_reset_btn:
        st.button("üóëÔ∏è Resetar Filtros", on_click=limpar_filtros_salvos, use_container_width=True)
    
    tab_base, tab_comparacao = st.tabs(["Filtros da BASE (Refer√™ncia)", "Filtros de COMPARA√á√ÉO (Alvo)"])

    def render_filter_panel(tab_container, suffix, colunas_filtro_a_exibir, df_analise_base):
        
        current_active_filters_dict = {}
        data_range = None # Garantimos que data_range seja None
        
        with tab_container:
            
            st.markdown("##### Filtros Categ√≥ricos")
            cols_container = st.columns(3) 
            
            # Defini√ß√£o da ordem de prioridade para melhor visualiza√ß√£o
            colunas_ordenadas = []
            priority_cols = ['emp', 'tipo_processo', 't', 'ano', 'mes'] 
            employee_col = 'nome_funcionario' 
            
            for col in colunas_filtro_a_exibir:
                if col in priority_cols: colunas_ordenadas.append(col)
            if employee_col in colunas_filtro_a_exibir: colunas_ordenadas.append(employee_col)
            for col in colunas_filtro_a_exibir:
                if col not in priority_cols and col != employee_col: colunas_ordenadas.append(col)
            
            colunas_ordenadas = list(dict.fromkeys(colunas_ordenadas)) 

            
            for i, col in enumerate(colunas_ordenadas):
                if col not in df_analise_base.columns: continue

                with cols_container[i % 3]:
                    filtro_key = f'filtro_key_{suffix}_{col}'
                    
                    # Usamos o DF COMPLETO para obter as op√ß√µes √∫nicas
                    opcoes_unicas_full = sorted(df_analise_base[col].astype(str).fillna('N/A').unique().tolist())
                    
                    if filtro_key not in st.session_state:
                         # Inicializa com todas as op√ß√µes selecionadas por default (nenhum filtro aplicado)
                         st.session_state[filtro_key] = opcoes_unicas_full 
                    
                    current_default = st.session_state.get(filtro_key, opcoes_unicas_full)
                    
                    # Garantir que o default n√£o tenha op√ß√µes que sumiram (seguran√ßa)
                    safe_default = [opt for opt in current_default if opt in opcoes_unicas_full]
                    st.session_state[filtro_key] = safe_default 

                    is_filtered = len(safe_default) > 0
                    is_all_selected = len(safe_default) == len(opcoes_unicas_full)
                    
                    label_status = "- ATIVO" if is_filtered and not is_all_selected else ("- INATIVO" if not is_filtered else "- TOTAL")

                    with st.expander(f"**{col.replace('_', ' ').title()}** {label_status}", expanded=False):
                        
                        col_all, col_none = st.columns(2)
                        with col_all:
                            st.button("Selecionar Tudo", key=f"select_all_{filtro_key}", use_container_width=True, 
                                     on_click=set_multiselect_all, args=(col, suffix, opcoes_unicas_full))
                        with col_none:
                            st.button("Limpar", key=f"select_none_{filtro_key}", use_container_width=True, 
                                     on_click=set_multiselect_none, args=(col, suffix))
                        
                        selected_options = st.multiselect(
                            f"Selecione as op√ß√µes para {col}:",
                            options=opcoes_unicas_full,
                            default=safe_default,
                            key=filtro_key,
                            label_visibility="collapsed"
                        )
                    
                    # Armazena a sele√ß√£o para a fun√ß√£o de caching e para o r√≥tulo
                    if selected_options:
                        current_active_filters_dict[col] = selected_options
                        
        return current_active_filters_dict, data_range

    # 1. Obter Filtros da BASE
    filtros_base_ativos, data_range_base = render_filter_panel(tab_base, 'base', colunas_categoricas_filtro, df_analise_completo)
    st.session_state.active_filters_base = filtros_base_ativos

    # 2. Obter Filtros da COMPARA√á√ÉO
    filtros_comp_ativos, data_range_comp = render_filter_panel(tab_comparacao, 'comp', colunas_categoricas_filtro, df_analise_completo)
    st.session_state.active_filters_comp = filtros_comp_ativos
    
    st.markdown("---")
    
    # 3. Aplicar os filtros (usando cache)
    df_base_filtrado, df_comp_filtrado = aplicar_filtros_comparacao(
        df_analise_completo, 
        colunas_categoricas_filtro, 
        st.session_state.active_filters_base, 
        st.session_state.active_filters_comp, 
        colunas_data, 
        None, # data_range_base
        None, # data_range_comp
        st.session_state.filtro_reset_trigger # Trigger para for√ßar rec√°lculo
    )

    # 4. Exibir a An√°lise Expert
    gerar_analise_expert(
        df_analise_completo, 
        df_base_filtrado, 
        df_comp_filtrado, 
        st.session_state.active_filters_base, 
        st.session_state.active_filters_comp, 
        colunas_data, 
        None, # data_range_base
        None  # data_range_comp
    )
